{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e28e5284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ddb4b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('file2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cd132164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = df.drop(columns = {'new_cases'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "209a7996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = df['new_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7fd7c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "433504fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_samples, valid_samples, train_labels, valid_labels = train_test_split(samples, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7dc7b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_samples, test_samples, train_labels, test_labels = train_test_split(train_samples, train_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "528b7edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.concat((train_samples,train_labels), axis = 1)\n",
    "# test = pd.concat((test_samples, test_labels), axis = 1)\n",
    "# valid = pd.concat((valid_samples, valid_labels), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "71e621db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv('train.csv',index=False)\n",
    "# test.to_csv('test.csv',index=False)\n",
    "# valid.to_csv('valid.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "faa2f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9bccc151",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = train.drop(columns = {'new_cases'})\n",
    "train_labels = train['new_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "27d57b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retail_and_recreation</th>\n",
       "      <th>residential</th>\n",
       "      <th>transit_stations</th>\n",
       "      <th>parks</th>\n",
       "      <th>workplaces</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases_smoothed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_deaths_smoothed</th>\n",
       "      <th>...</th>\n",
       "      <th>reproduction_rate</th>\n",
       "      <th>new_tests</th>\n",
       "      <th>total_tests</th>\n",
       "      <th>total_tests_per_thousand</th>\n",
       "      <th>new_tests_per_thousand</th>\n",
       "      <th>new_tests_smoothed</th>\n",
       "      <th>new_tests_smoothed_per_thousand</th>\n",
       "      <th>positive_rate</th>\n",
       "      <th>tests_per_case</th>\n",
       "      <th>stringency_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-85.857</td>\n",
       "      <td>28.286</td>\n",
       "      <td>-66.143</td>\n",
       "      <td>-63.714</td>\n",
       "      <td>-59.857</td>\n",
       "      <td>24530.0</td>\n",
       "      <td>1454.000</td>\n",
       "      <td>780.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>42.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.41</td>\n",
       "      <td>41247.0</td>\n",
       "      <td>541789.0</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.030</td>\n",
       "      <td>29524.0</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.049</td>\n",
       "      <td>20.3</td>\n",
       "      <td>96.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-39.143</td>\n",
       "      <td>13.429</td>\n",
       "      <td>-30.714</td>\n",
       "      <td>-45.286</td>\n",
       "      <td>-22.714</td>\n",
       "      <td>5562663.0</td>\n",
       "      <td>90346.714</td>\n",
       "      <td>88935.0</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>1165.571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>731534.0</td>\n",
       "      <td>64392594.0</td>\n",
       "      <td>46.661</td>\n",
       "      <td>0.530</td>\n",
       "      <td>1021881.0</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.088</td>\n",
       "      <td>11.3</td>\n",
       "      <td>83.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-67.857</td>\n",
       "      <td>17.000</td>\n",
       "      <td>-43.143</td>\n",
       "      <td>-55.286</td>\n",
       "      <td>-32.857</td>\n",
       "      <td>216824.0</td>\n",
       "      <td>8391.143</td>\n",
       "      <td>6088.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>222.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24</td>\n",
       "      <td>137158.0</td>\n",
       "      <td>4103233.0</td>\n",
       "      <td>2.973</td>\n",
       "      <td>0.099</td>\n",
       "      <td>123010.0</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.068</td>\n",
       "      <td>14.7</td>\n",
       "      <td>87.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-27.429</td>\n",
       "      <td>11.429</td>\n",
       "      <td>-8.571</td>\n",
       "      <td>-14.857</td>\n",
       "      <td>-12.571</td>\n",
       "      <td>10450284.0</td>\n",
       "      <td>18045.571</td>\n",
       "      <td>150999.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>223.429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>916951.0</td>\n",
       "      <td>180253315.0</td>\n",
       "      <td>130.618</td>\n",
       "      <td>0.664</td>\n",
       "      <td>901665.0</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.020</td>\n",
       "      <td>50.0</td>\n",
       "      <td>68.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-76.143</td>\n",
       "      <td>21.571</td>\n",
       "      <td>-52.429</td>\n",
       "      <td>-57.857</td>\n",
       "      <td>-43.571</td>\n",
       "      <td>106475.0</td>\n",
       "      <td>4597.571</td>\n",
       "      <td>3302.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>126.714</td>\n",
       "      <td>...</td>\n",
       "      <td>1.32</td>\n",
       "      <td>101475.0</td>\n",
       "      <td>2404267.0</td>\n",
       "      <td>1.742</td>\n",
       "      <td>0.074</td>\n",
       "      <td>92098.0</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.050</td>\n",
       "      <td>20.0</td>\n",
       "      <td>81.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   retail_and_recreation  residential  transit_stations   parks  workplaces  \\\n",
       "0                -85.857       28.286           -66.143 -63.714     -59.857   \n",
       "1                -39.143       13.429           -30.714 -45.286     -22.714   \n",
       "2                -67.857       17.000           -43.143 -55.286     -32.857   \n",
       "3                -27.429       11.429            -8.571 -14.857     -12.571   \n",
       "4                -76.143       21.571           -52.429 -57.857     -43.571   \n",
       "\n",
       "   total_cases  new_cases_smoothed  total_deaths  new_deaths  \\\n",
       "0      24530.0            1454.000         780.0        59.0   \n",
       "1    5562663.0           90346.714       88935.0      1053.0   \n",
       "2     216824.0            8391.143        6088.0       259.0   \n",
       "3   10450284.0           18045.571      150999.0       429.0   \n",
       "4     106475.0            4597.571        3302.0       146.0   \n",
       "\n",
       "   new_deaths_smoothed  ...  reproduction_rate  new_tests  total_tests  \\\n",
       "0               42.000  ...               1.41    41247.0     541789.0   \n",
       "1             1165.571  ...               0.99   731534.0   64392594.0   \n",
       "2              222.000  ...               1.24   137158.0    4103233.0   \n",
       "3              223.429  ...               0.92   916951.0  180253315.0   \n",
       "4              126.714  ...               1.32   101475.0    2404267.0   \n",
       "\n",
       "   total_tests_per_thousand  new_tests_per_thousand  new_tests_smoothed  \\\n",
       "0                     0.393                   0.030             29524.0   \n",
       "1                    46.661                   0.530           1021881.0   \n",
       "2                     2.973                   0.099            123010.0   \n",
       "3                   130.618                   0.664            901665.0   \n",
       "4                     1.742                   0.074             92098.0   \n",
       "\n",
       "   new_tests_smoothed_per_thousand  positive_rate  tests_per_case  \\\n",
       "0                            0.021          0.049            20.3   \n",
       "1                            0.740          0.088            11.3   \n",
       "2                            0.089          0.068            14.7   \n",
       "3                            0.653          0.020            50.0   \n",
       "4                            0.067          0.050            20.0   \n",
       "\n",
       "   stringency_index  \n",
       "0             96.30  \n",
       "1             83.80  \n",
       "2             87.50  \n",
       "3             68.98  \n",
       "4             81.94  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "423f7fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "503d9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "5a89ab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extractor\n",
    "def getFeatureRepresentation(x):\n",
    "    tensors = tf.convert_to_tensor(x, dtype = float)\n",
    "    model = models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(26,)))\n",
    "    model.add(layers.Dense(160, activation='tanh'))\n",
    "    model.add(layers.Dense(80, activation='tanh'))\n",
    "    model.compile()\n",
    "    feature_representation = model.predict(x = tensors)\n",
    "    return feature_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "478a63e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "train_feature_repr = getFeatureRepresentation(train_samples)\n",
    "val_feature_repr = getFeatureRepresentation(valid_samples)\n",
    "test_feature_repr = getFeatureRepresentation(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "337f85ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267, 80)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_repr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "199738ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task Label Generator\n",
    "def taskLabelGenerator(feature_repr, labels):\n",
    "    \n",
    "    labels = labels.to_numpy()\n",
    "    labels = np.reshape(labels, (labels.size, 1))\n",
    "    \n",
    "    feaRepLabel = np.concatenate((feature_repr, labels), axis = 1)\n",
    "    tensors = tf.convert_to_tensor(feaRepLabel, dtype = float)\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(81,)))\n",
    "    model.add(layers.Dense(160))\n",
    "    model.add(layers.Dense(128))\n",
    "    model.add(layers.Dense(80))\n",
    "    model.compile()\n",
    "    task_labels = model.predict(x = tensors)\n",
    "    task_label_mean = np.average(task_labels, axis = 0)\n",
    "    layer = layers.Softmax()\n",
    "    task_label = layer(task_label_mean).numpy()\n",
    "    return task_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "1d83e271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "train_task_label = taskLabelGenerator(train_feature_repr, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "79433b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_task_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "504843ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weights Generator\n",
    "def weightsGenerator(feature_repr, labels, task_label):\n",
    "    \n",
    "    labels = labels.to_numpy()\n",
    "    labels = np.reshape(labels, (labels.size, 1))\n",
    "    \n",
    "    task_label = np.reshape(task_label, (1,80))\n",
    "    task_label = np.tile(task_label, (labels.size, 1))\n",
    "    \n",
    "    feaRepLabelTaskLabel = np.concatenate((feature_repr, labels, task_label), axis = 1)\n",
    "    tensor = tf.convert_to_tensor(feaRepLabelTaskLabel, dtype = float)\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(161,)))\n",
    "    model.add(layers.Dense(256))  \n",
    "    model.add(layers.Dense(164))\n",
    "    model.add(layers.Dense(80))\n",
    "    model.compile()\n",
    "    weights = model.predict(x = tensor)\n",
    "    weight_mean = np.average(weights, axis = 0)\n",
    "    return weight_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "11602b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "weights = weightsGenerator(train_feature_repr, train_labels, train_task_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "bd0081ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.dot(train_feature_repr, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "33aa3039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "7611f029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115629.65041137255"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms = mean_squared_error(train_labels, result, squared=False)\n",
    "rms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d72c9da",
   "metadata": {},
   "source": [
    "Adding Self Attention Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "50e6eef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_self_attention\n",
      "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from keras_self_attention) (1.23.5)\n",
      "Building wheels for collected packages: keras_self_attention\n",
      "  Building wheel for keras_self_attention (setup.py): started\n",
      "  Building wheel for keras_self_attention (setup.py): finished with status 'done'\n",
      "  Created wheel for keras_self_attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=390feab15ba0047f253ddfb50017dff4bd1b928ce9cae34da07b80240f4e7e49\n",
      "  Stored in directory: c:\\users\\administrator\\appdata\\local\\pip\\cache\\wheels\\78\\c1\\84\\b83a2fd6f1d63e136cba74bac4126bee3b8705eef6486635fd\n",
      "Successfully built keras_self_attention\n",
      "Installing collected packages: keras_self_attention\n",
      "Successfully installed keras_self_attention-0.51.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_self_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b650d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras_self_attention import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe604058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selfAttentionBlock(model, embedding, residual_connection):\n",
    "    model.add(SeqSelfAttention(attention_activation = 'sigmoid'))\n",
    "    model.add(layers.Dense(128, activation = 'relu'))\n",
    "    model.add(layers.Dense(64))\n",
    "    output = model.add(layers.LayerNormalization(axis=1))\n",
    "    model.layers.Add()([embedding, output])\n",
    "    model.compile()\n",
    "    output = model.predict(embedding)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "061064e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task Label Generator\n",
    "def taskLabelGenerator(feature_repr, labels):\n",
    "    \n",
    "    labels = labels.to_numpy()\n",
    "    labels = np.reshape(labels, (labels.size, 1))\n",
    "    \n",
    "    feaRepLabel = np.concatenate((feature_repr, labels), axis = 1)\n",
    "    tensor = tf.convert_to_tensor(feaRepLabel, dtype = float)\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    \n",
    "    #First Layer\n",
    "    model.add(tf.keras.Input(shape=(41,)))\n",
    "    \n",
    "    #Second Layer\n",
    "    embedding = model.add(layers.Dense(64))\n",
    "    \n",
    "    #First Self-Attention Block\n",
    "    tensor = selfAttentionBlock(model, embedding, embedding)\n",
    "    \n",
    "    #Second Self-Attention Block\n",
    "    tensor = selfAttentionBlock(model, tensor, embedding)\n",
    "    \n",
    "    #Third Self-Attention Block\n",
    "    tensor = selfAttentionBlock(model, tensor, embedding)\n",
    "    \n",
    "    #Final Layer\n",
    "    model.add(layer.Dense(40))\n",
    "    \n",
    "    model.compile()\n",
    "    task_labels = model.predict(x = tensor)\n",
    "    \n",
    "    #Taking mean of all task labels\n",
    "    task_label_mean = np.average(task_labels, axis = 0)\n",
    "    \n",
    "    #Applying Softmax\n",
    "    layer = layers.Softmax()\n",
    "    task_label = layer(task_label_mean).numpy()\n",
    "    return task_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c37fa054",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21128\\1998495473.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_task_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtaskLabelGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_feature_repr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21128\\396945333.py\u001b[0m in \u001b[0;36mtaskLabelGenerator\u001b[1;34m(feature_repr, labels)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m#First Self-Attention Block\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselfAttentionBlock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m#Second Self-Attention Block\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21128\\3737324142.py\u001b[0m in \u001b[0;36mselfAttentionBlock\u001b[1;34m(model, embedding, residual_connection)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mselfAttentionBlock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresidual_connection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeqSelfAttention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_activation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    955\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_v2_behavior\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    958\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "train_task_label = taskLabelGenerator(train_feature_repr, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bda4285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e13e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weights Generator\n",
    "def weightsGenerator(feature_repr, labels, task_label):\n",
    "    \n",
    "    labels = labels.to_numpy()\n",
    "    labels = np.reshape(labels, (labels.size, 1))\n",
    "    \n",
    "    task_label = np.reshape(task_label, (1,40))\n",
    "    task_label = np.tile(task_label, (labels.size, 1))\n",
    "    \n",
    "    feaRepLabelTaskLabel = np.concatenate((feature_repr, labels, task_label), axis = 1)\n",
    "    tensor = tf.convert_to_tensor(feaRepLabelTaskLabel, dtype = float)\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    \n",
    "    #First Layer\n",
    "    model.add(tf.keras.Input(shape=(81,)))\n",
    "    \n",
    "    #Second Layer\n",
    "    embedding = model.add(layers.Dense(64))\n",
    "    \n",
    "    #First Self-Attention Block\n",
    "    tensor = selfAttentionBlock(embedding, embedding)\n",
    "    \n",
    "    #Second Self-Attention Block\n",
    "    tensor = selfAttentionBlock(tensor, embedding)\n",
    "    \n",
    "    #Third Self-Attention Block\n",
    "    tensor = selfAttentionBlock(tensor, embedding)\n",
    "    \n",
    "    #Final Layer\n",
    "    model.add(layers.Dense(40))\n",
    "    \n",
    "    model.compile()\n",
    "    weights = model.predict(x = tensor)\n",
    "    \n",
    "    #Taking mean of all the weights\n",
    "    weight_mean = np.average(weights, axis = 0)\n",
    "    return weight_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3885ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c339ded3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
